{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Replicating the BARTScore Results for Summarization from \"Evaluating Generated Text as Text Generation\" by Weizhe Yuan, Graham Neubig, and Pengfei Liu\n\nThe objective of this project was to replicate the results from the paper \"Evaluating Generated Text as Text Generation\" by Weizhe Yuan, Graham Neubig, and Pengfei Liu, specifically for the summarization task. For this purpose, we utilized the datasets provided on GitHub at : https://github.com/neulab/BARTScore/tree/main/SUM, as recommended in the paper.\n\nThe project is divided into three parts:\n\nDataset Analysis: In the first part, we explored the datasets to understand their structure and components.\n\nCustom BART Scorer: In the second part, we implemented a custom (vanilla version) BART scorer from scratch to evaluate the summarization quality.\n\nEvaluation and Comparison: In the final part, we computed evaluation scores using several metrics mentioned in the paper, including ROUGE-1, ROUGE-2, ROUGE-L, BertScore, MoverScore, and PRISM. We then compared the results obtained from these metrics with the scores from our custom BARTScore implementation and the scores provided in the dataset.\n\n","metadata":{"id":"O8WA3iq2enrq"}},{"cell_type":"markdown","source":"## 1. Dataset Analysis","metadata":{"id":"ltXF5oAJh4e0"}},{"cell_type":"code","source":"! pip install rouge_score evaluate torch transformers \n! pip install moverscore pyemd pytorch_pretrained_bert\n! pip install bert-score\nfrom scipy.stats import spearmanr\nimport requests\nimport pickle\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport torch\nimport evaluate\nfrom nltk.tokenize import sent_tokenize\nimport random\nimport pandas as pd\nfrom moverscore import word_mover_score, get_idf_dict\nimport numpy as np\nfrom bert_score import BERTScorer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:47:40.514233Z","iopub.execute_input":"2024-12-07T09:47:40.514621Z","iopub.status.idle":"2024-12-07T09:48:06.130444Z","shell.execute_reply.started":"2024-12-07T09:47:40.514586Z","shell.execute_reply":"2024-12-07T09:48:06.129348Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: moverscore in /opt/conda/lib/python3.10/site-packages (1.0.3)\nRequirement already satisfied: pyemd in /opt/conda/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: pytorch_pretrained_bert in /opt/conda/lib/python3.10/site-packages (0.6.2)\nRequirement already satisfied: typing in /opt/conda/lib/python3.10/site-packages (from moverscore) (3.7.4.3)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from moverscore) (3.0.0)\nRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from pyemd) (1.26.4)\nRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2.4.0)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (1.26.100)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (4.66.4)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2024.5.15)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2024.6.0)\nRequirement already satisfied: botocore<1.30.0,>=1.29.100 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (1.29.165)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (0.6.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (2024.6.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch_pretrained_bert) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch_pretrained_bert) (1.16.0)\nRequirement already satisfied: bert-score in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.4.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.46.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.26.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2024.6.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"### 1.a For the NeR18 dataset","metadata":{"id":"ml1sENEGh-Qw"}},{"cell_type":"code","source":"# URLs of the raw real_summ files\nurls = {\n    'summ_eval.pkl': 'https://raw.githubusercontent.com/neulab/BARTScore/main/SUM/SummEval/data.pkl',\n}\n\n# Download each file\nfor filename, url in urls.items():\n    response = requests.get(url)\n    if response.status_code == 200:\n        with open(filename, 'wb') as f:\n            f.write(response.content)\n        print(f'Successfully downloaded {filename}')\n    else:\n        print(f'Failed to download {filename} from {url}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:02:14.087328Z","iopub.execute_input":"2024-12-07T09:02:14.087729Z","iopub.status.idle":"2024-12-07T09:02:14.307967Z","shell.execute_reply.started":"2024-12-07T09:02:14.087695Z","shell.execute_reply":"2024-12-07T09:02:14.307011Z"}},"outputs":[{"name":"stdout","text":"Successfully downloaded summ_eval.pkl\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"with open('real_summ.pkl', 'rb') as f:\n    real_summ = pickle.load(f)\n    print(type(real_summ))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alnLT_3J45rS","outputId":"446632cc-8c6f-4e86-c9bd-71b39001152e","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:02:28.585003Z","iopub.execute_input":"2024-12-07T09:02:28.585345Z","iopub.status.idle":"2024-12-07T09:02:28.596469Z","shell.execute_reply.started":"2024-12-07T09:02:28.585316Z","shell.execute_reply":"2024-12-07T09:02:28.595596Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"def print_structure(d, indent=0):\n    \"\"\"\n    Recursively prints the structure of keys and subkeys in a hierarchical format.\n    :param d: The dictionary to traverse\n    :param indent: The current level of indentation for hierarchy\n    \"\"\"\n    for key, value in d.items():\n        print(\"  \" * indent + f\"- {key}\")\n        if isinstance(value, dict):  # If the value is another dictionary, recurse\n            print_structure(value, indent + 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:02:32.500628Z","iopub.execute_input":"2024-12-07T09:02:32.500972Z","iopub.status.idle":"2024-12-07T09:02:32.505933Z","shell.execute_reply.started":"2024-12-07T09:02:32.500943Z","shell.execute_reply":"2024-12-07T09:02:32.505036Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"random_element_real_summ = random.choice(list(real_summ.values()))\nprint_structure(random_element_real_summ)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:02:34.223244Z","iopub.execute_input":"2024-12-07T09:02:34.223957Z","iopub.status.idle":"2024-12-07T09:02:34.229275Z","shell.execute_reply.started":"2024-12-07T09:02:34.223923Z","shell.execute_reply":"2024-12-07T09:02:34.228257Z"}},"outputs":[{"name":"stdout","text":"- src\n- ref_summ\n- sys_summs\n  - presumm_out_trans_abs.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - two_stage_rl_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - unilm_out_v2.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - t5_out_large.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - presumm_out_ext_abs.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - ptr_generator_out_pointer_gen_cov.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - bart_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - fast_abs_rl_out_rerank.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - t5_out_11B.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - presumm_out_abs.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - bottom_up_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - unilm_out_v1.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - t5_out_base.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - semsim_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - neusumm_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - pnbert_out_lstm_pn_rl.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - refresh_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - heter_graph_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - pnbert_out_bert_tf_sl.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - banditsumm_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - pnbert_out_bert_lstm_pn_rl.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - pnbert_out_bert_tf_pn.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - matchsumm_out.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n  - pnbert_out_bert_lstm_pn.txt\n    - sys_summ\n    - scores\n      - litepyramid_recall\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"## 2. Custom BART Scorer","metadata":{"id":"wGFwy5XAlIb3"}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"id":"X0oh12snr4Ye","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T07:36:13.844758Z","iopub.execute_input":"2024-12-07T07:36:13.845367Z","iopub.status.idle":"2024-12-07T07:36:13.906288Z","shell.execute_reply.started":"2024-12-07T07:36:13.845316Z","shell.execute_reply":"2024-12-07T07:36:13.905342Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Build our custom Bart Scorer which uses pretrainned BART\nclass CustomBartScorer:\n    def __init__(self, model_name=\"facebook/bart-large-cnn\", device=device):\n        \"\"\"\n        Initialize the tokenizer and model for computing BartScore.\n        Args:\n            model_name (str): Pretrained BART model checkpoint.\n            device (str): Device to run computations\n        \"\"\"\n        self.device = device\n        self.tokenizer = BartTokenizer.from_pretrained(model_name)\n        self.model = BartForConditionalGeneration.from_pretrained(model_name)\n        self.model.to(device)\n        self.model.eval()\n\n    def compute_log_probs(self, src_text, tgt_text):\n        \"\"\"\n        Compute the log probabilities of the target text given the source text.\n        Args:\n            src_text (str): Source text\n            tgt_text (str): Target text\n        Returns:\n            log_prob (float): The log probability of the target text.\n        \"\"\"\n        # Tokenize source and target texts\n        src_inputs = self.tokenizer(src_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True).to(self.device)\n        tgt_inputs = self.tokenizer(tgt_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True).to(self.device)\n\n        # Forward pass with source as input and target as labels\n        with torch.no_grad():\n            outputs = self.model(**src_inputs, labels=tgt_inputs[\"input_ids\"])\n            logits = outputs.logits  # Logits: (batch_size, seq_len, vocab_size)\n\n        # Compute log probabilities using log-softmax\n        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n\n        # Gather log probabilities of the target tokens\n        tgt_token_ids = tgt_inputs[\"input_ids\"]\n        tgt_mask = tgt_inputs[\"attention_mask\"]\n        seq_len = tgt_mask.sum(dim=1)\n\n        # Collect log probabilities for the correct target tokens\n        tgt_log_probs = log_probs.gather(2, tgt_token_ids.unsqueeze(-1)).squeeze(-1)\n\n        # Mask out padding tokens and sum log probabilities\n        tgt_log_probs = tgt_log_probs * tgt_mask\n        total_log_probs = tgt_log_probs.sum(dim=1)\n\n        # Normalize by sequence length\n        normalized_log_probs = total_log_probs / seq_len\n\n        return normalized_log_probs.item()\n\n    def compute_bartscore(self, src, tgt):\n        \"\"\"\n        Compute BartScore for a given source and target text.\n        Args:\n            src (str): Source text.\n            tgt (str): Target text.\n        Returns:\n            score (float): BartScore value.\n        \"\"\"\n        return self.compute_log_probs(src, tgt)\n","metadata":{"id":"Fq5h9zabEH9K","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T07:36:17.160751Z","iopub.execute_input":"2024-12-07T07:36:17.161114Z","iopub.status.idle":"2024-12-07T07:36:17.170269Z","shell.execute_reply.started":"2024-12-07T07:36:17.161084Z","shell.execute_reply":"2024-12-07T07:36:17.169299Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"scorer = CustomBartScorer(model_name=\"facebook/bart-large-cnn\", device=\"cuda\")","metadata":{"id":"Svu9eXJIEQ6T","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T07:36:19.961993Z","iopub.execute_input":"2024-12-07T07:36:19.962348Z","iopub.status.idle":"2024-12-07T07:36:31.268339Z","shell.execute_reply.started":"2024-12-07T07:36:19.962316Z","shell.execute_reply":"2024-12-07T07:36:31.267467Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ef32ce5e1a4432bc4ed92798e0b38e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d71f23abc03f4d3da74d13f59a7935a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e822abaf43b48e28c1f35b4de1d1ad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738ec47455bd42b583679f6cadb6079a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6fb93ba69be4c7c818334222cb31cda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea3fba2ce5eb4b3c9df1b1daec1f031f"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## 3. Evaluation and Comparison\n","metadata":{"id":"8GBqzmUBl4mI"}},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")","metadata":{"id":"jpuOXOmrMAOU","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T07:36:33.476085Z","iopub.execute_input":"2024-12-07T07:36:33.477033Z","iopub.status.idle":"2024-12-07T07:36:33.912124Z","shell.execute_reply.started":"2024-12-07T07:36:33.476989Z","shell.execute_reply":"2024-12-07T07:36:33.911375Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Store ROUGE, Bertscore, Prism, Moverscore and BartScore results\nrouge1_scores = []\nrouge2_scores = []\nrougeL_scores = []\nbart_scores = []\n\n# Loop over each element in our dataset\nfor element in real_summ.values():\n    src = element[\"src\"]\n    ref_summ = element[\"ref_summ\"]\n    sys_summary = element[\"sys_summs\"]\n\n    # For each system summary variant (fragments, textrank, etc.), compute ROUGE and BartScore\n    for key, sys_sum_dict in sys_summary.items():\n        sys_sum = sys_sum_dict[\"sys_summ\"]\n        scores = sys_sum_dict[\"scores\"]\n\n        # Compute ROUGE score\n        rouge_result = rouge.compute(predictions=[sys_sum], references=[ref_summ])\n\n        # Store Rouge1 / Rouge2 / RougeL scores\n        rouge1_score = rouge_result['rouge1']\n        rouge2_score = rouge_result['rouge2']\n        rougeL_score = rouge_result['rougeL']\n\n        # Compute BartScore\n        bart_score = scorer.compute_bartscore(src, sys_sum)\n\n        # Compute BERTSCORE\n\n        # Append the results\n        rouge1_scores.append(rouge1_score)\n        rouge2_scores.append(rouge2_score)\n        rougeL_scores.append(rougeL_score)\n        bart_scores.append(bart_score)","metadata":{"id":"VO58U_UBP7n4","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T07:36:35.301568Z","iopub.execute_input":"2024-12-07T07:36:35.302048Z","iopub.status.idle":"2024-12-07T07:45:11.024105Z","shell.execute_reply.started":"2024-12-07T07:36:35.301998Z","shell.execute_reply":"2024-12-07T07:45:11.023334Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"sys_summary_rnd = random_element[\"sys_summs\"]\nsys_summary_rnd.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:33:14.760027Z","iopub.execute_input":"2024-12-07T08:33:14.760370Z","iopub.status.idle":"2024-12-07T08:33:14.765915Z","shell.execute_reply.started":"2024-12-07T08:33:14.760340Z","shell.execute_reply":"2024-12-07T08:33:14.765036Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"dict_keys(['presumm_out_trans_abs.txt', 'two_stage_rl_out.txt', 'unilm_out_v2.txt', 't5_out_large.txt', 'presumm_out_ext_abs.txt', 'ptr_generator_out_pointer_gen_cov.txt', 'bart_out.txt', 'fast_abs_rl_out_rerank.txt', 't5_out_11B.txt', 'presumm_out_abs.txt', 'bottom_up_out.txt', 'unilm_out_v1.txt', 't5_out_base.txt', 'semsim_out.txt', 'neusumm_out.txt', 'pnbert_out_lstm_pn_rl.txt', 'refresh_out.txt', 'heter_graph_out.txt', 'pnbert_out_bert_tf_sl.txt', 'banditsumm_out.txt', 'pnbert_out_bert_lstm_pn_rl.txt', 'pnbert_out_bert_tf_pn.txt', 'matchsumm_out.txt', 'pnbert_out_bert_lstm_pn.txt'])"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"    # Retrieve and store the score of \"litepyramid_recall\", \n    # as it is the only key inside the \"scores\" it must correspond to the COV on the table\n    cov = []\n    \n    for element in real_summ.values():\n        src = element[\"src\"]\n        ref_summ = element[\"ref_summ\"]\n        sys_summary = element[\"sys_summs\"]\n    \n        # Loop over the different summarization methods (presumm_out_trans_abs, two_stage_rl_out, etc.)\n        for key, sys_sum_dict in sys_summary.items():\n    \n            # append the scores to their corresponding lists\n            # as this is the only score provided, it must correspond to COV\n            cov.append(sys_sum_dict['scores'][\"litepyramid_recall\"]) ","metadata":{"id":"SzrNvNJDXZuV","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:35:53.097820Z","iopub.execute_input":"2024-12-07T08:35:53.098418Z","iopub.status.idle":"2024-12-07T08:35:53.103895Z","shell.execute_reply.started":"2024-12-07T08:35:53.098383Z","shell.execute_reply":"2024-12-07T08:35:53.102935Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# MoverScore","metadata":{}},{"cell_type":"code","source":"# Initialize lists to store generated summaries and reference summaries\ngenerated_texts = []\nreference_texts = []\n\n# Iterate through the dataset to extract generated and reference texts\nfor element in real_summ.values():\n    ref_summ = element['ref_summ']  # Reference summary\n    sys_summaries = element['sys_summs']  # System-generated summaries collection\n\n    for sys_name, sys_data in sys_summaries.items():\n        sys_summ = sys_data['sys_summ']  # Extract system-generated summary\n\n        # Add generated and reference texts to the respective lists\n        generated_texts.append(sys_summ)\n        reference_texts.append(ref_summ)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Calculate the IDF for reference and generated summaries\nidf_reference = get_idf_dict(reference_texts)\nidf_generated = get_idf_dict(generated_texts)\n\n# Calculate MoverScore\nmover_scores = word_mover_score(\n    reference_texts,          # List of reference summaries\n    generated_texts,          # List of generated summaries\n    idf_reference,            # IDF dictionary for reference texts\n    idf_generated,            # IDF dictionary for generated texts\n    stop_words=[],            # Stopwords, typically used to remove non-essential words\n    n_gram=1,                 # Use n-gram, default is 1 (unigram)\n    remove_subwords=True,     # Whether to remove subwords\n    batch_size=8,             # Batch size, adjust to improve calculation speed\n    device='cuda'             # Choose computing device, e.g., 'cuda' or 'cpu'\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:53:21.312665Z","iopub.execute_input":"2024-12-07T09:53:21.313004Z","iopub.status.idle":"2024-12-07T09:55:01.303762Z","shell.execute_reply.started":"2024-12-07T09:53:21.312975Z","shell.execute_reply":"2024-12-07T09:55:01.302642Z"}},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":"# BERTScore","metadata":{}},{"cell_type":"code","source":"# initialize BERTScorer\nscorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n\n# calculate BERTScore\nP, R, F = scorer.score(generated_texts, reference_texts)\n\n# Calculate Spearman correlation between ROUGE-1 and COH\ncorr, p_value = spearmanr(F, coh)\n\nprint(f\"Spearman correlation of BERTScore: {corr}\")\nprint(f\"P-value of BERTScore: {p_value}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a dictionary to store the real_summ\ncorrelation_real_summ = {}\n\n# Define the metrics and human evaluation scores\nmetrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BartScore', 'MoverScore', 'BERTScore']\nhuman_scores = ['cov']\n\n# Calculate Spearman correlations\nfor metric in metrics:\n    correlation_data[metric] = {}\n    if metric == 'ROUGE-1':\n        metric_scores = rouge1_scores\n    elif metric == 'ROUGE-2':\n        metric_scores = rouge2_scores\n    elif metric == 'ROUGE-L':\n        metric_scores = rougeL_scores\n    elif metric == 'BartScore':\n        metric_scores = bart_scores\n    elif metric == 'MoverScore':\n        metric_scores = mover_scores\n    elif metric == 'BERTScore':\n        metric_scores = F\n    for human_score in human_scores:\n        if human_score == 'cov':\n            scores = cov\n            \n        correlation, _ = spearmanr(metric_scores, scores)\n        correlation_data[metric][human_score] = correlation\n\n# Create the DataFrame\ncorrelation_df = pd.DataFrame.from_dict(correlation_data, orient='index')\n\n# Display the DataFrame\ncorrelation_df","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ke08gTtVZYLd","outputId":"fb0bb308-569c-4173-bc73-ddb0ce815862","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:00:16.667175Z","iopub.execute_input":"2024-12-07T10:00:16.667970Z","iopub.status.idle":"2024-12-07T10:00:16.694899Z","shell.execute_reply.started":"2024-12-07T10:00:16.667932Z","shell.execute_reply":"2024-12-07T10:00:16.693827Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                 cov\nROUGE-1     0.454249\nROUGE-2     0.467728\nROUGE-L     0.431196\nBartScore   0.129514\nMoverScore  0.430399\nBERTScore   0.441452","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cov</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ROUGE-1</th>\n      <td>0.454249</td>\n    </tr>\n    <tr>\n      <th>ROUGE-2</th>\n      <td>0.467728</td>\n    </tr>\n    <tr>\n      <th>ROUGE-L</th>\n      <td>0.431196</td>\n    </tr>\n    <tr>\n      <th>BartScore</th>\n      <td>0.129514</td>\n    </tr>\n    <tr>\n      <th>MoverScore</th>\n      <td>0.430399</td>\n    </tr>\n    <tr>\n      <th>BERTScore</th>\n      <td>0.441452</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":74}]}